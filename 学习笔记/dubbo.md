基本原则

采用Microkernel + Plugin模式，Microkernel只负责组将Plugin，Dubbo自身的功能也是通过扩展点实现的，也就是Dubbo的所有功能点都可被用户自定义扩展所替换。
采用URL作为配置信息的统一格式，所有扩展点都通过传递URL携带配置信息。

1. 接口参数设置：超时时间，重试次数，最大并发调用，负载均衡，是否异步，延迟初始化。

讲到线程模型，实现上密切相关的Dubbo网络连接模型必须要提一下。Dubbo默认是所有服务共享单一的TCP长连接的（这也是为什么服务接口不适合传输大负载值，即容易阻塞其他服务的调用）。为响应慢或重要的服务接口考虑，Dubbo支持设置多TCP连接，此时连接数和线程池数默认是绑定的，即每连接对应一个线池，consumer、provider都执行这个策略，从线程隔离的角度讲是合理的，但不注意也容易造成线程占用资源过多，尤其是对于消费端基本无线程阻塞的情况下可能是一个设计缺陷。

3. 服务动态治理

动态治理本质上是依赖Dubbo运行期参数的动态调整，再通用一点其实就是应用的参数动态调整，开源常用的disconf、diamond、archaius等集中配置管理工具都是设计来解决这个问题。Dubbo内部在url参数传递模型基础上实现了一套参数动态配置逻辑，个人认为相比于Dubbo的实现，集成disconf等更专业的框架应该是更好的解决方案，或许Dubbo为了一些其他设计目标解除了对一些外部框架的强制依赖。动态治理可以实现从基本参数如timeout、mock到一些高级特性如路由、限流等几乎所有的运行期参数调整。

Dubbo原生在动态配置上存在很多bug，配置不生效或配置规则误读等问题都遇到过，如果你再使用原生Dubbo过程中也遇到任何配置问题，Dubbok应该都已经解决掉了。


3. 负载均衡
负载均衡策略上Dubbo原生提供的有基于权重随机负载、最少活跃数优先、Roundrobin、一致性Hash等几个方案。

2. 路由、集群容错、限流

和负载均衡策略一样，Dubbo的路由方案是集成在消费端的，加上集群容错功能客户端相对是一个重量的功能封装。可选方案是将路由工作移到注册中心完成（这要求注册中心具有较强的可定制性，不仅路由像权限控制、服务过滤、环境隔离等都可由注册中心集成）

限流目前支持consumer、provider端并发限流，实际上是基于信号量限制的，以接口粒度分配信号量，当信号量用完新的调用将被拒绝，当业务返回后信号量被释放。

消费端限流应该是为整个提供端集群分配信号量，而Dubbo错误的将信号量分配给单个机器。这个问题目前可以通过下文提到的隔离框架的流控功能来实现。
限流并非精确限制，不应当依赖其实现严格的并发数控制。
后端backend服务限流需要业务方合理评估每个接口的流控值，要求对业务量有足够经验值（可能要在多次线上调优后才能最终得出合理的流控值）。考拉内部流控实践证明，对于保证服务稳定性、优先保证重要消费方、实现服务隔离等有着重要的作用。

一下是dubbo路由规则：

路由规则

	2.2.0以上版本支持
	路由规则扩展点：路由扩展
向注册中心写入路由规则：(通常由监控中心或治理中心的页面完成)

RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();
Registry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));
registry.register(URL.valueOf("condition://0.0.0.0/com.foo.BarService?category=routers&dynamic=false&rule=" + URL.encode("http://10.20.160.198/wiki/display/dubbo/host = 10.20.153.10 => host = 10.20.153.11") + "));
其中：

condition://
表示路由规则的类型，支持条件路由规则和脚本路由规则，可扩展，必填。
0.0.0.0
表示对所有IP地址生效，如果只想对某个IP的生效，请填入具体IP，必填。
com.foo.BarService
表示只对指定服务生效，必填。
category=routers
表示该数据为动态配置类型，必填。
dynamic=false
表示该数据为持久数据，当注册方退出时，数据依然保存在注册中心，必填。
enabled=true
覆盖规则是否生效，可不填，缺省生效。
force=false
当路由结果为空时，是否强制执行，如果不强制执行，路由结果为空的路由规则将自动失效，可不填，缺省为flase。
runtime=false
是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。
如果用了参数路由，必须设为true，需要注意设置会影响调用的性能，可不填，缺省为flase。
priority=1
路由规则的优先级，用于排序，优先级越大越靠前执行，可不填，缺省为0。
rule=URL.encode("host = 10.20.153.10 => host = 10.20.153.11")
表示路由规则的内容，必填。
条件路由规则
(#)

基于条件表达式的路由规则，如：

host = 10.20.153.10 => host = 10.20.153.11
规则：

+ "=>"之前的为消费者匹配条件，所有参数和消费者的URL进行对比，当消费者满足匹配条件时，对该消费者执行后面的过滤规则。
+ "=>"之后为提供者地址列表的过滤条件，所有参数和提供者的URL进行对比，消费者最终只拿到过滤后的地址列表。
+ 如果匹配条件为空，表示对所有消费方应用，如：=> host != 10.20.153.11
+ 如果过滤条件为空，表示禁止访问，如：host = 10.20.153.10 =>
表达式：

参数支持：

服务调用信息，如：method, argument 等 (暂不支持参数路由)
URL本身的字段，如：protocol, host, port 等
以及URL上的所有参数，如：application, organization 等

条件支持：

等号"="表示"匹配"，如：host = 10.20.153.10
不等号"!="表示"不匹配"，如：host != 10.20.153.10

值支持：

以逗号","分隔多个值，如：host != 10.20.153.10,10.20.153.11
以星号"*"结尾，表示通配，如：host != 10.20.*
以美元符"$"开头，表示引用消费者参数，如：host = $host

示例：

1. 排除预发布机：

=> host != 172.22.3.91
2. 白名单：(注意：一个服务只能有一条白名单规则，否则两条规则交叉，就都被筛选掉了)

host != 10.20.153.10,10.20.153.11 =>
3. 黑名单：

host = 10.20.153.10,10.20.153.11 =>
4. 服务寄宿在应用上，只暴露一部分的机器，防止整个集群挂掉：

=> host = 172.22.3.1*,172.22.3.2*
5. 为重要应用提供额外的机器：

application != kylin => host != 172.22.3.95,172.22.3.96
6. 读写分离：

method = find*,list*,get*,is* => host = 172.22.3.94,172.22.3.95,172.22.3.96
method != find*,list*,get*,is* => host = 172.22.3.97,172.22.3.98
7. 前后台分离：

application = bops => host = 172.22.3.91,172.22.3.92,172.22.3.93
application != bops => host = 172.22.3.94,172.22.3.95,172.22.3.96
8. 隔离不同机房网段：

host != 172.22.3.* => host != 172.22.3.*
9. 提供者与消费者部署在同集群内，本机只访问本机的服务：

=> host = $host

三、依赖隔离（服务降级）

当应用被设计依赖外部服务时，要始终保持警惕状态：外部依赖是不稳定的，为此对接外部依赖做好解耦是关键，避免外部接口发生异常拖垮自身系统。Dubbo提供了超时timeout机制作为最基本的解耦措施，同时在接口报错时支持提供降级的容错逻辑；除了容错降级，Dubbo进一步支持强制的短路降级。

然而在容错降级与短路降级之间，Dubbo缺乏一种在容错与短路间切换的机制，即自动熔断。自动熔断要达到的效果是：当接口偶然报错时执行容错返回备用数据，而当接口持续大量报错时能自动在消费端对接口调用短路直接返回备用数据，之后持续监测接口可用性，接口恢复后自动恢复调用。这样能最大限度减少接口异常对消费方的影响，同时也减轻本就处于异常状态的提供端负载。

Dubbok通过标准SPI的的形式，实现了熔断功能。目前支持两套方案：一套是自己实现的熔断逻辑；一套是通过集成hystrix框架实现。目前支持错误率、最低请求量、熔断时间窗等基本配置，支持将业务异常纳入统计范畴；以上参数均可通过SOA治理平台运行期动态调整；支持外部Dubbo依赖调用的准实时监控。

1.延迟暴露。

默认Dubbo服务会随着Spring框架的加载逐一完成服务到注册中心的注册（暴露），如果某些服务需要等待资源就位才能暴露，那就需要延时注册。

2.启动预热

一些应用在运行期会通过本地缓存中间结果提升性能，而当此类应用重启时本地缓存数据丢失，如果重启后的机器立即有大量请求导流过来，由于没有缓存加速会导致请求阻塞响应性能降低。通过对重启后的机器设置预热期可有效缓解重启缓存失效问题：具体做法是降低预热期内的机器权重，引导少部分流量到此机器，此机器可以在预热期内逐步建立缓存，待预热期过后恢复正常权重与其他机器平均分摊流量。

3.优雅停机

在集群部署的情况下，单个消费者或提供者机器上下线对整个产品的运转应该是近乎无感知的，Dubbo提供了优雅停机功机制保障在进程关闭前请求都得到妥善处理。

消费方优雅停机：控制不再有新的请求发出；等待已经发出的请求正确返回；释放连接等资源。

提供方优雅停机：通知消费端停止发送请求到当前机器；通知注册中心服务下线；等待已经接收的请求处理完成并返回；释放连接等资源。

考拉在每次服务上下线过程中，每个工程总是收到大量的消费方/提供方报出的服务调用异常，经排查是Dubbo优雅停机实现的问题，修复问题后工程上线阶段异常数明显减少。
另外停机阶段总是莫名的收到zk连接为空的异常信息。是由于在通知注册中心服务下线的过程中，Spring销毁线程和jvm hook线程并发执行，导致zk客户端被提前销毁导致抛出异常。

4.Provider重启

注册中心发送大量服务销毁与注册通知导致consumer工程Full GC。

历史原因，考拉内部仍存在一个提供近200个Dubbo服务的单体工程，而每次当这个工程上线时，消费它的consumer工程就会出现频繁Full GC（3-5次，非内存泄露）。

是Dubbo为保证高可用而设计的注册中心缓存导致的问题：在每次收到注册中心变更时consumer会在本地磁盘保存一份服务数据副本，由于多注册中心共享同一份缓存文件，为了避免相互覆盖，每个注册中心实例会在收到变更时重新从磁盘加载文件到缓存，和变更数据对比后重新写回磁盘，在近100提供者机器不断重启的过程中，大量的变更通知导致的频繁加载缓存文件占用大量内存导致Full GC。

五、Dubbok近期优化目标:

+ 提供端线程池隔离，解决提供端线程池阻塞等问题；优化消费端线程池分配方案
+ 服务治理动态配置功能增加应用、机器粒度的配置
+ 多注册中心消费端负载均衡策略
+ Dubbo内部资源JMX监控
+ 结合SOA平台优化监控统计数据：错误类型细分（超时、限流、网络异常等）；执行时间细分如90%、99% RT等；统计占 用线程数较多的服务、传送数据量较大的服务，为分线程池或连接做参考
+ 对Spring boot推行的Javaconfig配置方式提供更友好、全面的注解支持
+ 一些框架升级，如Javassist、Netty等
+ 替代Zookeeper的高性能、可扩展注册中心
+ 服务安全、授权问题调研
+ Spring Cloud的一些优秀特性将作为Dubbok改进的一个持续关注点


4. 共享连接
+ 长连接
+ 多路复用

DubboProtocol特有功能，默认开启
JVM A暴露了多个服务，JVM B引用了A中的多个服务，共享连接是说A与B多个服务调用是通过同一个TCP长连接进行数据传输，已达到减少服务端连接数的目的.
实现细节：对于同一个地址由于使用了共享连接，那invoker的destroy就需要特别注意，一方面要满足对同一个地址refer的invoker全部destroy后，连接需要关闭，另一方面还需要注意如何避免部分invoker destroy时不能关闭连接。在实现中采用了引用计数的方案，但为了防范，在连接关闭时，重新建立了一个Lazy connection(称为幽灵连接),用于当出现异常场景时，避免影响业务逻辑的正常调用.

5. 服务提供者选择逻辑
1.存在多个服务提供者的情况下，首先根据Loadbalance进行选择，如果选择的provider处于可用状态，则进行后续调用
2.如果第一步选择的服务提供者不可用，则从剩余服务提供者列表中继续选择，如果可用，进行后续调用
3.如果所有的服务提供者都不可用，重新遍历整个列表（优先从没有选过的列表中选择），判断是否有可用的服务提供者（选择过程中，不可用的服务提供者可能会恢复到可用状态），如果有，则进行后续调用
4.如果第三步没有选择出可用的服务提供者，会选第一步选出的invoker中的下一个（如果不是最后一个），避免碰撞.

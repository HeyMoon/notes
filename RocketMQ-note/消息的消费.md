在RocketMQ中Consumer有两种，一种是Push Consumer，一种是Pull Consumer。消费方式又有BROADCASTING和CLUSTERING两种。

+ Push Consumer：应用通常向Consumer对象注册一个Listener接口，一旦受到消息，Consumer对象立即回调Listener接口方法。

+ Pull Consumer：应用通常主动调用Consumer的拉消息方法从Broker拉消息，主动权由应用控制。

+ BROADCASTING 消费：广播消费，一条消息被多个Consumer消费,即使这些Consumer属于同一个Consumer Group,消息也会被Consumer Group 中的每个Consumer都消费一次,广播消费中的Consumer Group概念可以认为在消息划分方面无意义。在 JMS 规范中,相当于JMS publish/subscribe model。

+ CLUSTERING 消费：集群消费，一个Consumer Group中的Consumer实例平均分摊消费消息。例如某个Topic有 9 条消息,其中一个Consumer Group 有 3 个实例(可能是 3 个进程,或者 3 台机器),那么每个实例只消费其中的 3 条消息。在 JMS 规范中,JMS point-to-point model 与之类似,但是 RocketMQ 的集群消费功能大等于 PTP 模型。 因为RocketMQ 单个Consumer Group内的消费者类似于 PTP,但是一个 Topic/Queue 可以被多个 Consumer Group 消费。

在这里我们以`DefaultMQPushConsumer`为例。一般，PushConsumer的代码如下所示：

````
public static void main(String[] args) throws InterruptedException, MQClientException {

    DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("CID_JODIE_1");


    consumer.subscribe("Jodie_topic_1023", "*");

    consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);

    consumer.registerMessageListener(new MessageListenerConcurrently() {

        @Override
        public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
            System.out.println(Thread.currentThread().getName() + " Receive New Messages: " + msgs);
            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
        }
    });


    consumer.start();

    System.out.println("Consumer Started.");
}
````

## PushConsumer start

`DefaultMQPushConsumer.start()`最终调用`DefaultMQPushConsumerImpl.start()`方法启动。

1. `this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook);`，创建`mQClientFactory`实例。

2. ` this.rebalanceImpl.setAllocateMessageQueueStrategy(new AllocateMessageQueueAveragely());` 这个类是分配Message Queue的策略。

3. offsetStore

    + 如果MessageModel是BROADCASTING,offsetStore为LocalFileOffsetStore。

    + 如果MessageModel是CLUSTERING,offsetStore为RemoteBrokerOffsetStore。

4. ConsumeMessageService

    + 如果之前注册的MessageListener是`MessageListenerOrderly`的实例，则ConsumeMessageService为ConsumeMessageOrderlyService,consumerOrderly = true.

    + 如果之前注册的MessageListener是`MessageListenerConcurrently`的实例，则ConsumeMessageService为ConsumeMessageConcurrentlyService,consumerOrderly = false.

5.  `consumeMessageService.start()`

     1. ConsumeMessageConcurrentlyService.start():启动定时任务，将过期的消息发送回broker.  

     2. ConsumeMessageOrderlyService.start()：如果MessageModel = CLUSTERING,启动定时任务，初始延迟1秒，每20秒执行一次：调用ConsumeMessageOrderlyService.this.lockMQPeriodically()。ConsumeMessageOrderlyService.this.lockMQPeriodically调用ConsumeMessageOrderlyService.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll()。

     ConsumeMessageOrderlyService.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll()的处理流程：

     (1)根据brokerName从`processQueueTable`中取出MessageQueue Set（为了之后的说明，命名为brokerMqs,`HashMap<String, Set<MessageQueue>> brokerMqs）`。`processQueueTable`存放的是Consumer从Broker拉下来的消息。

     (2)遍历brokerMqs，取出`Set<MessageQueue>`，根据BrokerName找到BrokerAddress。

     (3)向BrokerAddress发起RequestCode.LOCK_BATCH_MQ请求,同步调用。等待服务端返回锁定好的MessageQueue集合lockOKMQSet。

     (4)如果一个MessageQueue既包含在lockOKMQSet中，也包含在processQueueTable中，那么processQueueTable中MessageQueue对应的ProcessQueue设置为已经锁定(locked = true)。如果一个MessageQueue包含在processQueueTable中，不包含在lockOKMQSet中，那么processQueueTable中对应的ProcessQueue设置为没有锁定(locked = false)。

     说的很绕，其实就是，ProcessQueue是Consumer根据topic和tag从Broker拉下来的数据，ProcessQueueTable中存放的是`ConcurrentHashMap<MessageQueue, ProcessQueue> processQueueTable`.再用MessageQueue向Broke发起锁定请求，如果服务端返回锁定成功，那么更新ProcessQueue为已经锁定(locked = true)；如果Broker没有锁定成功，则设置ProcessQueue为没有锁定(locked = false)。

     Broker 端锁定的流程：
     Broker端维护了一个全局的消息队列锁定表：`ConcurrentHashMap<String（group）, ConcurrentHashMap<MessageQueue, LockEntry>> mqLockTable`。

     锁定流程如下：

     (1)先根据ConsumerGroup从mqLockTable取出 ConcurrentHashMap<MessageQueue, LockEntry> groupValue ，groupValue == null则，new ConcurrentHashMap<MessageQueue,LockEntry> 放入mqLockTable中。

     (2)再根据mq从ConcurrentHashMap中取出LockEntry，如果LockEntry为null则new LockEntry，lockEntry.setClientId(clientId)，将LockEntry放入groupValue中。

     (3)向Consumer返回已经锁定的lockOKMQSet。

     **总结一下，如果是ConsumeMessageOrderlyService，start方法的作用就是Consumer从ProcessQueueTable<MessageQueue,ProcessQueue> 中取出MessageQueue，向Broker申请锁定这个MessageQueue，如果Broker锁定成功,Consumer更新对应的ProcessQueue为Locked**

     **Broker会维护一个全局的`ConcurrentHashMap<String（group）, ConcurrentHashMap<MessageQueue, LockEntry>> mqLockTable`，key为ConsumerGroup,LockEntry中存放相应的ClientId**

6. mQClientFactory.registerConsumer()：将consumer放入consumerTable中。     

7. mQClientFactory.start()

   1. this.mQClientAPIImpl.start()。启动netty channel。启动定时任务扫描responseTable。

   2. 启动各种定时任务

   3. pullMessageService.start()。启动PullMessageService
      调用pullRequestQueue.take()，阻塞直到PullRequest不为null。调用DefaultMQPushConsumerImpl.pullMessage(pullRequest)。

      DefaultMQPushConsumerImpl.pullMessage处理流程：

      (1)从pullRequest中取出ProcessQueue,如果processQueue.isDropped(),return;

      (2)设置processQueue的lastPullTimeStamp = system.currentTimeMillis()，这个时间和processQueue锁的过期时间有关。

      (3)如果不是consumerOrderly，50毫秒后，将pullRequest放入pullRequestQueue.

      (4)如果是consumerOrderly，并且processQueue.islocked(),并且pullRequest.isLockedFirst 为false，则final long offset = this.rebalanceImpl.computePullFromWhere(pullRequest.getMessageQueue())，计算下一次从Broker拉数据的偏移量。
      pullRequest.setLockedFirst(true); pullRequest.setNextOffset(offset);

      (5)如果是consumerOrderly,并且processQueue.islocked()为false，50毫秒后，将pullRequest放入pullRequestQueue.

      (6)根据topic，从subscriptionInner中找订阅信息，如果没有找到，则50毫秒后，将pullRequest放入pullRequestQueue.

      (7)this.pullAPIWrapper.pullKernelImpl()，异步调用，调用之后执行pullcallback。这个方法的作用是去服务端批量拉数据，batchSize = 32.

      pullKernelImpl()处理流程:

          (1)根据MessageQueue计算从哪个broker node pull.默认是BrokerId为0，即Master。

          (2)根据brokerName,BrokerId从brokerAddrTable找到brokerAddr.如果没有找到,则从nameserver更新brokerAddr.

          (3)如果要过滤信息，则根据topic,brokerAddr找到filterServerAddr.

          (5)调用this.mQClientFactory.getMQClientAPIImpl().pullMessage()

             (1)this.remotingClient.invokeAsync(),RequestCode.PULL_MESSAGE

             (2)回调pullcallback处理返回的PullResult.

                (1) FOUND:

                    (a) PullResult.getMsgFoundList为空。说明Broker还没有这个Topic的消息，将pullRequest放入pullRequestQueue中，重新拉。

                    (b) PullResult.getMsgFoundList不为空。说明从Broker拉到了数据。

                         1.processQueue.putMessage(pullResult.getMsgFoundList());

                         2.consumeMessageService.submitConsumeRequest()，这个方法最终都是调用consumeRequest的run方法，但是有不同的实现。

                         ConsumeMessageConcurrentlyService的实现：

                             调用MessageListenerConcurrently.consumeMessage()。就是调用在Consumer中注册的Listener消费消息。

                         ConsumeMessageOrderlyService的实现：

                             A.如果MessageModel.CLUSTERING并且processQueue没有锁定或者锁过期了，10秒后重新向Broker发起锁定请求，并且 将pullRequest放入pullRequestQueue中。锁的有效期是30秒，超过30秒就过期了。

                             B.processQueue.takeMessags(consumeBatchSize)。从processQueue中取出消息。

                             C.this.processQueue.getLockConsume().lock();获取processQueue的锁。

                             D.调用messageListener.consumeMessage()消费消息。

                             E.this.processQueue.getLockConsume().unlock();释放processQueue的锁

                          **C,E 可以保证客户端只有一个线程可以消费消息**

                         3.将pullRequest放入pullRequestQueue中。

                (2) NO_NEW_MSG或者NO_MATCHED_MSG，立即将pullRequest放入pullRequestQueue。

                (3) OFFSET_ILLEGAL.

      Broker端的处理有一个需要注意的地方：

      (1)获取suspendTimeoutMillisLong（20秒）,挂起超时时间，在没有拉取到消息时，这个标识决定是否立即返回Consumer。如果获取允许长轮询，并且有这个标识，则会等待suspendTimeoutMillisLong时间。具体来说就是：new pullRequest,加入到pullRequestHoldService的pullRequestTable,等Producer有消息到时，再通知取消息。


  4. RebalanceService.start(),启动Rebalance Service。
     遍历consumerTable中的MQConsumerInner,依次调用MQConsumerInner.doRebalance().MQConsumerInner调用RebalanceImpl.doRebalance(boolean isOrder).

     RebalanceImpl.doRebalance(boolean isOrder).处理流程：
     遍历`Map<String /* topic */, String /* sub expression */>`subscriptionInner，依次调用rebalanceByTopic(topic,isOrder)方法

     rebalanceByTopic(topic,isOrder)方法处理流程：

     (1)如果MessageModel是BROADCASTING。根据topic从`ConcurrentHashMap<String/* topic */, Set<MessageQueue>> topicSubscribeInfoTable`中取出Set<MessageQueue> mqSet,调用updateProcessQueueTableInRebalance方法，方法处理如下：

         遍历processQueueTable<MessageQueue, ProcessQueue>

         a. 如果这个topic所对应的MessageQueue在topicSubscribeInfoTable中而不在ProcessQueue中，设置processQueueTable中对应的ProcessQueue的dropped为true。调用removeUnnecessaryMessageQueue(MessageQueue,ProcessQueue)方法。具体处理逻辑如下：

             A.根据brokerName找到brokerAddr,向brokerAddr发起UPDATE_CONSUMER_OFFSET请求，oneway。broker端，ClientManageProcessor.processRequest()处理请求:从offsetTable中以"topic@group"为key找出对应的<queueId,offset>map,更新queueId对应的offset。

             B.先从RemoteBrokerOffsetStore.offsetTable中remove这个mq，再向broker发送RequestCode.UNLOCK_BATCH_MQ请求。one way。

             A、B是RebalancePullImpl的处理流程，如果是RebalancePushImpl，则还有以下流程：

             C.是否是顺序消费(consumerOrderly)并且MessageModel是CLUSTERING,Lock ProcessQueue,调用this.unlockDelay(mq, pq);方法处理如下：

             判断pq.hasTempMessage()，即ProcessQueue中是否还有消息没消费，如果有，则20秒后调用this.unlock(mq,true).
             如果没有temp message则直接调用unlock()方法。

             unlock方法处理逻辑如下：

             根据brokerName和masterId(0)在brokerAddrTable中找到brokerAddr.如果找到了，则调用this.mQClientFactory.getMQClientAPIImpl().unlockBatchMQ().
             RequestCode.UNLOCK_BATCH_MQ，oneway.

             broker端的处理如下：

             根据consumerGroup从mqLockTable中获取对应的ConcurrentHashMap<MessageQueue, LockEntry> groupValue ,如果groupValue不为null，则遍历groupValue中的MessageQueue，获取对应的LockEntry(LockEntry中存有clientId),如果LockEntry中的clientId和请求中的clientId一致，则将这个MessageQueue从groupValue中remove。

         b. 或者，pq.isPullExpired()?如果过期了

            （1）如果消费类型是PULL，则break。

            （2）如果消费类型是PUSH，则：processQueue.setDroped(true),再调用removeUnnecessaryMessageQueue()方法。   

        遍历完ProcessQueue之后，再遍历MessageQueueSet，处理每一个MessageQueue.

        a.如果processQueueTable中不包含这个MessageQueue

            (1)如果isOrder为true（顺序消费）

                (1)向broker发送lock MessageQueue请求。如果broker返回lockFail，则处理下一个MessageQueue.

                (2)如果broker 返回lock成功，则从offsetTable中remove这个MessageQueue.        

            (2)调用computePullFromWhere(mq)方法，返回从哪里消费的consumeOffset.

                这个方法RebalancePullImpl直接返回0，RebalancePushImpl的处理相对复杂。这个方法和`consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);`息息相关。

            (3)如果上一步的computePullFromWhere方法返回的nextOffset >=0,则ProcessQueue pre = processQueueTable.putIfAbsent(mq,new ProcessQueue())。

            (4)如果上一步的pre == null,则new PullRequest(),将这个PullRequest添加到PullRequestList中。

            (5)调用dispatchPullRequest(pullRequestList)方法。

                dispatchPullRequest:RebalancePullImpl为空方法。

                dispatchPullRequest:RebalancePushImpl,遍历pullRequestList,依次调用this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest)，将pullRequest放入pullMessageService的pullRequestQueue中。

     到这里updateProcessQueueTableInRebalance方法处理完毕。

     (2)如果MessageModel是CLUSTERING。

         先根据topic从topicSubscribeInfoTable中找出`Set<MessageQueue>`

         再根据topic和consumerGroup找到所有的consumerId.

         如果MessageQueue和ConsumerId都不为null，则调用AllocateMessageQueueStrategy.allocate()方法，（AllocateMessageQueueStrategy有4种，默认是AllocateMessageQueueAveragely，平均分配），分配MessageQueue。

         再调用updateProcessQueueTableInRebalance方法。


8. this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();
   给所有的broker 发送心跳；更新filter 类源。

9. this.mQClientFactory.rebalanceImmediately();
   唤醒rebalanceService，执行mqClientFactory.doRebalance();方法，过程和上面的rebalanceService一样。

## PullConsumer start
一般，PullConsumer 的代码如下：

```
public class PullConsumer {
    private static final Map<MessageQueue, Long> offseTable = new HashMap<MessageQueue, Long>();


    public static void main(String[] args) throws MQClientException {
        DefaultMQPullConsumer consumer = new DefaultMQPullConsumer("please_rename_unique_group_name_5");

        consumer.start();

        Set<MessageQueue> mqs = consumer.fetchSubscribeMessageQueues("TopicTest1");
        for (MessageQueue mq : mqs) {
            System.out.println("Consume from the queue: " + mq);
            SINGLE_MQ:
            while (true) {
                try {
                    PullResult pullResult =
                            consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32);
                    System.out.println(pullResult);
                    putMessageQueueOffset(mq, pullResult.getNextBeginOffset());
                    switch (pullResult.getPullStatus()) {
                        case FOUND:
                            break;
                        case NO_MATCHED_MSG:
                            break;
                        case NO_NEW_MSG:
                            break SINGLE_MQ;
                        case OFFSET_ILLEGAL:
                            break;
                        default:
                            break;
                    }
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }

        consumer.shutdown();
    }

    private static long getMessageQueueOffset(MessageQueue mq) {
        Long offset = offseTable.get(mq);
        if (offset != null)
            return offset;

        return 0;
    }

    private static void putMessageQueueOffset(MessageQueue mq, long offset) {
        offseTable.put(mq, offset);
    }

}
```

DefaultMQPullConsumerImpl.start():

1. mQClientFactory.registerConsumer
以group为key,MQConsumerInner为Value放入consumerTable中

2. mQClientFactory.start()
 MQClientInstance.start().和PushConsumer一样。


consumer.fetchSubscribeMessageQueues:

1. 根据topic从NameServer找到topicRouteData，根据topicRouteData中的QueueData，创建对应数量的MessageQueue，返回MessageQueueList.

consumer.pullBlockIfNotFound：

最终调用DefaultMQPUpullSyncImpl.pullSyncImpl();

    1. 根据brokerName找到brokerAddr.

    2. 同步调用，RequestCode.PULL_MESSAGE。

    broker端处理：PullMessageProcessor.processRequest()-->DefaultMessageStore.getMessage():

    根据topic和queueId,从consumeQueueTable中取出对应的consumeQueue，再根据offset从ConsumeQueue中取出对应的Consume Queue,映射为mappedFile.
    遍历mappedFile中从offset到limit。

    （1）调用messageFilter.isMessageMatched(),对比consumeQueue中的tagsCode和订阅的tagsCode，这里对比的是tagsCode的hashcode.如果符合，则调  用CommitLog.getMessage(),根据consumeQueue中对应的offset从CommitLog中取出对应的消息。

    **所以取一个消息要取两次，先从consumeQueue中取，再从CommitLog中取**

    如果brokerRole不是slave,并且longPollingEnable = true，则调用`pullRequestHoldService.notifyMessageArriving()`  
       这里调用PullMessageProcessor.processRequest：

````
    if (this.brokerController.getBrokerConfig().isSlaveReadEnable()) {
         // consume too slow ,redirect to another machine
         if (getMessageResult.isSuggestPullingFromSlave()) {
             responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly());
         }
         // consume ok
         else {
             responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getBrokerId());
         }
     }

    long diff = maxOffsetPy - maxPhyOffsetPulling;
    long memory = (long) (StoreUtil.TotalPhysicalMemorySize
                                    * (this.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / 100.0));
    getResult.setSuggestPullingFromSlave(diff > memory);


    public static long getTotalPhysicalMemorySize() {
        long physicalTotal = 1024 * 1024 * 1024 * 24;
        OperatingSystemMXBean osmxb = ManagementFactory.getOperatingSystemMXBean();
        if (osmxb instanceof com.sun.management.OperatingSystemMXBean) {
            physicalTotal = ((com.sun.management.OperatingSystemMXBean) osmxb).getTotalPhysicalMemorySize();
        }

        return physicalTotal;
    }
````

    如果diff > 总物理内存的40%，则重定向到Slave.

    （2）循环调用过程(1)

返回pullResult,根据订阅时的tag和返回的pullResult对比(这里对比的是String.equals())，剔除tag不合的数据，返回剔除后的pullResult.


>传入一个startIndex，如何找到对应的consume queue呢？
首先，因为Consume Queue中的存储单元是定长的（20字节）所以offset = startIndex * 20。找到了offset ,因为每个文件都是定长的，所以offset/文件大小就知道offset所对应的文件的index,在减去mappedFileQueue中第一个文件的index，就可以得到这个文件在mappedFileQueue中的index.
比如offset = 45，每个文件大小为10,第一个文件的为000，那么offset对应的文件就是第四个文件。45 - 4*10=5，这个5就是第四个文件的取消息的开始位置。

## Push and Pull
Push 和 Pull 本质都是 Pull。

1. Push方式里，Consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。

   我们先忽略PushConsumer启动时顺序消息的相关服务和过程,就可以串出整个Push的过程。

   具体分析如下：

   1. 首先是RebalanceService的处理：

       (1)RebalanceService启动，Consumer遍历consumerTable中的`MQConsumerInner`,依次调用MQConsumerInner.doRebalance().MQConsumerInner调用RebalanceImpl.doRebalance(boolean isOrder).

       (2)再遍历`Map<String /* topic */, String /* sub expression */>`subscriptionInner，subscriptionInner存的是订阅的topic和expression。根据topic从`ConcurrentHashMap<String/* topic */, Set<MessageQueue>> topicSubscribeInfoTable`中取出`Set<MessageQueue>` mqSet

       (3)调用computePullFromWhere(mq)，返回消费的offset。这一步和`consumer.setConsumeFromWhere();`设置息息相关。

       (4)processQueueTable.putIfAbsent(mq,new ProcessQueue())。

       (5)new PullRequest(),将这个PullRequest添加到pullRequestQueue中。

   2. 接着是PullMessageService的处理：

       (6)调用pullRequestQueue.take()，阻塞直到PullRequest不为null。调用DefaultMQPushConsumerImpl.pullMessage(pullRequest)。

       (7)this.pullAPIWrapper.pullKernelImpl()，异步调用，调用之后执行pullcallback。这个方法的作用是去服务端批量拉数据，batchSize = 32.

       pullKernelImpl()处理流程:

           (1)根据MessageQueue计算从哪个broker node pull.默认是BrokerId为0，即Master。

           (2)根据brokerName,BrokerId从brokerAddrTable找到brokerAddr.如果没有找到,则从nameserver更新brokerAddr.

           (3)如果要过滤信息，则根据topic,brokerAddr找到filterServerAddr.

           (5)调用this.mQClientFactory.getMQClientAPIImpl().pullMessage()

              (1)this.remotingClient.invokeAsync(),RequestCode.PULL_MESSAGE

              (2)回调pullcallback处理返回的PullResult.
                  (1) FOUND:

                      (a) PullResult.getMsgFoundList为空。说明Broker还没有这个Topic的消息，将pullRequest放入pullRequestQueue中，重新拉。

                      (b) PullResult.getMsgFoundList不为空。说明从Broker拉到了数据。

                           1.processQueue.putMessage(pullResult.getMsgFoundList());

                           2.consumeMessageService.submitConsumeRequest()，这个方法最终都是调用consumeRequest的run方法，但是有不同的实现。

                           ConsumeMessageConcurrentlyService的实现：

                               **调用MessageListenerConcurrently.consumeMessage()。就是调用在Consumer中注册的Listener消费消息。**

                           ConsumeMessageOrderlyService的实现：

                               A.如果MessageModel.CLUSTERING并且processQueue没有锁定或者锁过期了，10秒后重新向Broker发起锁定请求，并且 将pullRequest放入pullRequestQueue中。锁的有效期是30秒，超过30秒就过期了。

                               B.processQueue.takeMessags(consumeBatchSize)。从processQueue中取出消息。

                               C.this.processQueue.getLockConsume().lock();获取processQueue的锁。

                               D.**调用messageListener.consumeMessage()消费消息。**

                               E.this.processQueue.getLockConsume().unlock();释放processQueue的锁

                            **C,E 可以保证客户端只有一个线程可以消费消息**

                           3.将pullRequest放入pullRequestQueue中。

                  (2) NO_NEW_MSG或者NO_MATCHED_MSG，立即将pullRequest放入pullRequestQueue。

                  (3) OFFSET_ILLEGAL.

上面就是Push的具体流程。                  

2. Pull方式里，取消息的过程需要用户自己写，首先通过打算消费的Topic拿到MessageQueue Set，遍历MessageQueue Set，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。(如上面的PullConsumer实例代码所示)

## BROADCASTING,CLUSTERING

+ BROADCASTING 消费：广播消费，一条消息被多个Consumer消费,即使这些Consumer属于同一个Consumer Group,消息也会被Consumer Group 中的每个Consumer都消费一次,广播消费中的Consumer Group概念可以认为在消息划分方面无意义。在 JMS 规范中,相当于JMS publish/subscribe model。

+ CLUSTERING 消费：集群消费，一个Consumer Group中的Consumer实例平均分摊消费消息。例如某个Topic有 9 条消息,其中一个Consumer Group 有 3 个实例(可能是 3 个进程,或者 3 台机器),那么每个实例只消费其中的 3 条消息。在 JMS 规范中,JMS point-to-point model 与之类似,但是 RocketMQ 的集群消费功能大等于 PTP 模型。 因为RocketMQ 单个Consumer Group内的消费者类似于 PTP,但是一个 Topic/Queue 可以被多个 Consumer Group 消费。

CLUSTERING的具体实现在`AllocateMessageQueueAveragely.allocate()`方法，关键代码如下：

```
public List<MessageQueue> allocate(String consumerGroup, String currentCID, List<MessageQueue> mqAll,
                                   List<String> cidAll) {

    int index = cidAll.indexOf(currentCID);
    int mod = mqAll.size() % cidAll.size();
    int averageSize =
            mqAll.size() <= cidAll.size() ? 1 : (mod > 0 && index < mod ? mqAll.size() / cidAll.size()
                    + 1 : mqAll.size() / cidAll.size());
    int startIndex = (mod > 0 && index < mod) ? index * averageSize : index * averageSize + mod;
    int range = Math.min(averageSize, mqAll.size() - startIndex);
    for (int i = 0; i < range; i++) {
        result.add(mqAll.get((startIndex + i) % mqAll.size()));
    }
    return result;
}
```

参数中`currentCID`表示当前客户端的Id，`mqall`表示某个topic的所有MessageQueue，`cidAll`表示ConsumerGroup中所有的客户端Id。

averageSize表示每个客户端可以分到多少个MessageQueue.

## 消费确认
我们在消费消息时可以返回一个消费状态，如下所示：

````
public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,
                                                ConsumeConcurrentlyContext context) {
    System.out.println(Thread.currentThread().getName() + " Receive New Messages: " + msgs);
    return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
}
});
````

消费确认主要就是处理返回的消息消费状态。ConsumeMessageConcurrentlyService和ConsumeMessageOrderlyService的处理不同：

ConsumeMessageConcurrentlyService:

1. 如果返回的ConsumeConcurrentlyStatus == null,则status = ConsumeConcurrentlyStatus.RECONSUME_LATER;。

2. 如果status == CONSUME_SUCCESS，则调用ConsumerStatsManager,记录相应consumerGroup和topic的消费成功数和失败数

3. 如果status == CONSUMER_LATER,则调用ConsumerStatsManager,记录相应consumerGroup和topic的消费失败数。

处理状态为CONSUMER_LATER的消息：

1. 如果消费模式是BROADCASTING,记录消费失败的消息到日志。

2. 如果消费模式是CLUSTERING，将失败的消息发送回Broker（topic不变），
如果发送到Broker失败，则将消息发送到topic为RETRY_TOPIC的message queue下。

ConsumeMessageOrderlyService：

1. 如果status == null,则，status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;

2. 是否自动提交（默认为true，即自动提交）

如果自动提交：

(1) 状态为COMMIT或ROLLBACK或SUCCESS,调用ProcessQueue的commit方法，清除msgTreeMapTemp。

(2) 状态为SUSPEND_CURRENT_QUEUE_A_MOMENT,如果重试次数大于16次，则将消息发送回Broker，topic为RETRY_TOPIC。

如果重试次数小于16次，则稍后重新消费消息.

如果不自动提交：

(1)状态为SUCCESS,则调用ConsumerStatsManager,记录相应consumerGroup和topic的消费成功数

(2)状态为COMMIT，则调用ProcessQueue的commit方法。

(3)状态为ROLLBACK，则调用ProcessQueue的rollback方法。稍后重新消费消息。

(4)状态为SUSPEND_CURRENT_QUEUE_A_MOMENT，消息发送回Broker，topic为RETRY_TOPIC。

## 顺序消息
顺序消息是指，消费消息的顺序要同发送消息的顺序一致。在RocketMQ中，要做到顺序消息，必须满足以下条件。

1. Producer单线程顺序发送,且发送到同一个队列。

2. Consumer单线程消费同一个队列。

我们知道Producer在发送消息时，会采用round-robin方式，从MessageQueue中轮流选择队列发送，每个队列接收平均的消息量。但是如果我们想把消息只发送到一个队列呢？

可以通过实现`MessageQueueSelector`指定要发送的队列。

```
public class Producer {

    public static void main(String[] args) throws MQClientException, RemotingException, InterruptedException, MQBrokerException {
        MQProducer producer = new DefaultMQProducer("order_message_group");
        producer.start();

        String[] tags = new String[]{"TagA","TagB","TagC"};

        for (int i = 0; i < 100; i++) {
             int orderId = i % 10;
            Message msg = new Message("TopicTestOrder",
                    tags[i % tags.length],
                    "KEY" + i,
                    ("Hello RocketMQ " + i).getBytes(Charset.forName("UTF-8")));

            SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
                public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
                    Integer id = (Integer) arg;
                    int index = id % mqs.size();
                    return mqs.get(index);
                }
            },orderId);//orderId就是消息队列的Id
            System.out.println(sendResult);

        }

        producer.shutdown();

    }
}
```

Consumer保证单线程消费同一个队列要如何实现？

其实在PushConsumer的start过程里，已经分析了顺序消息的实现，只不过和Push混杂在一起，可能不是很清晰，这里再分析一遍。

PushConsumer启动时，有三个关键服务启动：`ConsumeMessageService`,`RebalanceService`,`PullMessageService`.

在上一节的`Push and Pull`中我们已经分析串起了`RebalanceService`,`PullMessageService`.`ConsumeMessageService`就和顺序消息有关。

### ConsumeMessageOrderlyService.start()

1. 锁定

如果MessageModel = CLUSTERING,启动定时任务，初始延迟1秒，每20秒执行一次：调用ConsumeMessageOrderlyService.this.lockMQPeriodically()。ConsumeMessageOrderlyService.this.lockMQPeriodically调用ConsumeMessageOrderlyService.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll()。

ConsumeMessageOrderlyService.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll()的处理流程：

    (1)根据brokerName从`processQueueTable`中取出MessageQueue Set（为了之后的说明，命名为brokerMqs,`HashMap<String, Set<MessageQueue>> brokerMqs`）。`processQueueTable`存放的是Consumer从Broker拉下来的消息。

    (2)遍历brokerMqs，取出`Set<MessageQueue>`，根据BrokerName找到BrokerAddress。

    (3)向BrokerAddress发起RequestCode.LOCK_BATCH_MQ请求,同步调用。等待服务端返回锁定好的MessageQueue集合lockOKMQSet。

    (4)如果一个MessageQueue既包含在lockOKMQSet中，也包含在processQueueTable中，那么processQueueTable中MessageQueue对应的ProcessQueue设置为已经锁定(locked = true)。如果一个MessageQueue包含在processQueueTable中，不包含在lockOKMQSet中，那么processQueueTable中对应的ProcessQueue设置为没有锁定(locked = false)。

    说的很绕，其实就是，ProcessQueue是Consumer根据topic和tag从Broker拉下来的数据，ProcessQueueTable中存放的是`ConcurrentHashMap<MessageQueue, ProcessQueue> processQueueTable`.再用MessageQueue向Broke发起锁定请求，如果服务端返回锁定成功，那么更新ProcessQueue为已经锁定(locked = true)；如果Broker没有锁定成功，则设置ProcessQueue为没有锁定(locked = false)。

    Broker 端锁定的流程：
    Broker端维护了一个全局的消息队列锁定表：`ConcurrentHashMap<String（group）, ConcurrentHashMap<MessageQueue, LockEntry>> mqLockTable`。

    锁定流程如下：

    (1)先根据ConsumerGroup从mqLockTable取出 `ConcurrentHashMap<MessageQueue, LockEntry> groupValue` ，groupValue == null则，`new ConcurrentHashMap<MessageQueue,LockEntry>` 放入mqLockTable中。

    (2)再根据mq从ConcurrentHashMap中取出LockEntry，如果LockEntry为null则new LockEntry，lockEntry.setClientId(clientId)，将LockEntry放入groupValue中。

    (3)向Consumer返回已经锁定的lockOKMQSet。

2. Consumer消费消息时

调用consumeMessageService.submitConsumeRequest()，这个方法最终都是调用consumeRequest的run方法，但是有不同的实现。

ConsumeMessageOrderlyService的实现：

    A.如果MessageModel.CLUSTERING并且processQueue没有锁定或者锁过期了，10秒后重新向Broker发起锁定请求，并且 将pullRequest放入pullRequestQueue中。锁的有效期是30秒，超过30秒就过期了。

    B.processQueue.takeMessags(consumeBatchSize)。从processQueue中取出消息。

    C.this.processQueue.getLockConsume().lock();获取processQueue的锁。

    D.**调用messageListener.consumeMessage()消费消息。**

    E.this.processQueue.getLockConsume().unlock();释放processQueue的锁

#### 总结

1. 如果是ConsumeMessageOrderlyService，Consumer从`ProcessQueueTable<MessageQueue,ProcessQueue>` 中取出MessageQueue，向Broker申请锁定这个MessageQueue，如果Broker锁定成功,Consumer更新对应的ProcessQueue为locked = true

2. Broker会维护一个全局的`ConcurrentHashMap<String（group）, ConcurrentHashMap<MessageQueue, LockEntry>> mqLockTable`，key为ConsumerGroup,LockEntry中存放相应的ClientId

3. Consumer消费消息时，使用`Lock lockConsume = new ReentrantLock();`加锁，保证单线程消费。

这样就实现了顺序消息

## Message Filter
消息过滤在Broker端进行。这样可以避免不必要的消息传递。

### 简单消息过滤
在`PullConsumer start`这一节，我们已经提到了简单消息过滤。在订阅时可以通过简单的表达式过滤消息，如下所示：

```
//订阅指定topic下tags分别等于TagA或TagC或TagD
consumer.subscribe("TopicTest1", "TagA || TagC || TagD");
```

我们知道ConsumeQueue的存储单元有20个字节，分别存储:commitLog offset(8字节)，msg size(4字节)，tagcode hashCode(8字节)。

在Consumer从Broker拉消息时：

+ 调用messageFilter.isMessageMatched(),对比consumeQueue中的tagsCode和订阅的tagsCode，这里对比的是tagsCode的hashcode.如果符合，则调  用CommitLog.getMessage(),根据consumeQueue中对应的offset从CommitLog中取出对应的消息。

Consumer获取到PullResult之后：

+ 根据订阅时的tag和返回的pullResult对比(这里对比的是String.equals())，剔除tag不合的数据，返回剔除后的pullResult.

为什么过滤要这样做?

1. Message Tag 存储 Hashcode,是为了在 Consume Queue 定长方式存储,节约空间。

2. 过滤过程中不会访问 Commit Log 数据,可以保证堆积情况下也能高效过滤。

3. 即使存在Hash冲突,也可以在Consumer端进行修正,保证万无一失。

### 高级消息过滤

#### Filter Server的创建
Broker启动时，会调用filterServerManger.start()。

   filterServerManger启动一个定时任务，初始延时5秒，每30秒执行一次，调用FilterServerManager.this.createFilterServer()：获取Broker的filterServerNums配置（默认是0），filterServerTable初始大小为0.
   more = filterServerNums - filterServerTable.size().如果more>0,则调用shell，创建FilterServer。

Consumer在订阅时，可以上传一个过滤Java类，如下列代码所示：

```
public class Consumer {

    public static void main(String[] args) throws InterruptedException, MQClientException {
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("ConsumerGroupNamecc4");

        String filterCode = MixAll.file2String("/home/admin/MessageFilterImpl.java");
        consumer.subscribe("TopicFilter7", "com.alibaba.rocketmq.example.filter.MessageFilterImpl",
                filterCode);

        consumer.registerMessageListener(new MessageListenerConcurrently() {

            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,
                                                            ConsumeConcurrentlyContext context) {
                System.out.println(Thread.currentThread().getName() + " Receive New Messages: " + msgs);
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });

        consumer.start();

        System.out.println("Consumer Started.");
    }
}
```

过滤的过程如下：

1. Broker所在的机器会启动多个FilterServer(如果filterServerNums > 0)过滤进程

2. Consumer启动后,会向FilterServer上传一个过滤的Java类

3. Consumer从FilterServer 拉消息,FilterServer将请求转发给Broker,FilterServer从Broker收到消息后,按照
Consumer上传的Java过滤程序做过滤,过滤完成后返回给Consumer。

总结:

1. 使用CPU资源来换取网卡流量资源

2. FilterServer与Broker部署在同一台机器,数据通过本地回环通信,不走网卡

3. 一台Broker部署多个FilterServer,充分利用CPU资源,因为单个Jvm难以全面利用高配的物理机CPU资源

4. 因为过滤代码使用Java语言来编写,应用几乎可以做任意形式的服务器端消息过滤,例如通过 Message Header
进行过滤,甚至可以按照 Message Body 进行过滤。

5. 使用Java语言进行作为过滤表达式是一个双刃剑,方便了应用的过滤操作,但是带来了服务器端的安全风险。
需要应用来保证过滤代码安全,例如在过滤程序里尽可能不做申请大内存,创建线程等操作。避免 Broker 服
务器发生资源泄漏。

参考：

RocketMQ_design.pdf
